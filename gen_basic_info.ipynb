{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52452f2c-a2b7-4c02-9926-b54f40d3a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import executorch\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df0da00-e002-4022-962f-6097cac2f119",
   "metadata": {},
   "source": [
    "## import all module\n",
    "we will first import all the modules from the package composed_module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046d0e89-b8a4-408b-be4c-24800ca9efe1",
   "metadata": {},
   "source": [
    "## test on alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "627927fe-0731-43ab-ba66-9b8a09a1ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.export import dynamic_dim\n",
    "from torch.export import Dim\n",
    "import executorch.exir as exir\n",
    "from torch._export import capture_pre_autograd_graph\n",
    "from torch.export import export, ExportedProgram\n",
    "from executorch.exir import EdgeProgramManager, to_edge\n",
    "from executorch.exir import ExecutorchBackendConfig, ExecutorchProgramManager\n",
    "from executorch.exir.passes import MemoryPlanningPass\n",
    "from torchvision.io import read_image\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import os\n",
    "# Step 1: Initialize model with the best available weights\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "# model = alexnet(weights=weights)\n",
    "model.eval()\n",
    "directory_path = './export_model'\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "directory_path = './model_detail'\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "directory_path = './input_weight'\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "directory_path = './golden'\n",
    "os.makedirs(directory_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006cc2cd-eded-4adc-b455-f1b96541b220",
   "metadata": {},
   "source": [
    "### generate the resnet pte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "827e15d9-1b20-4144-8c37-21605613bfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/executorch/lib/python3.10/site-packages/torch/utils/_pytree.py:590: UserWarning: pytree_to_str is deprecated. Please use treespec_dumps\n",
      "  warnings.warn(\"pytree_to_str is deprecated. Please use treespec_dumps\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "example_args = (torch.randn(1, 3, 224, 224),)\n",
    "def edge_transform(model: nn.Module , example_args , name : str):\n",
    "    try:\n",
    "        os.chdir('./export_model')\n",
    "        pre_autograd_aten_dialect = capture_pre_autograd_graph(model, example_args)\n",
    "        aten_dialect: ExportedProgram = export(pre_autograd_aten_dialect, example_args)\n",
    "        edge_program: EdgeProgramManager = to_edge(aten_dialect)\n",
    "        executorch_program: ExecutorchProgramManager = edge_program.to_executorch(\n",
    "            ExecutorchBackendConfig(\n",
    "                passes=[],  # User-defined passes\n",
    "                memory_planning_pass=MemoryPlanningPass(\n",
    "                    \"greedy\"\n",
    "                ),  # Default memory planning pass\n",
    "            )\n",
    "        )        \n",
    "        with open(f'{name}.pte', \"wb\") as file:\n",
    "            file.write(executorch_program.buffer)\n",
    "        os.chdir('../') # return to origin \n",
    "    except:\n",
    "        print('error!')\n",
    "\n",
    "    \n",
    "edge_transform(model, example_args , \"resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cf936c-7c50-4863-a36e-f0d912775fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def summary(model, input_size, batch_size=-1, device=torch.device('cpu'), dtypes=None):\n",
    "    layers_param , layers , result, params_info = summary_string(\n",
    "        model, input_size, batch_size, device, dtypes)\n",
    "    os.chdir('./model_detail')\n",
    "    with open('module_overview.txt', 'w') as file:\n",
    "        file.write(result)\n",
    "        file.write('\\n')\n",
    "        file.write('total weight = ')\n",
    "        file.write(str(params_info[0]))\n",
    "        file.write('trainable weight = ')\n",
    "        file.write(str(params_info[1]))\n",
    "    os.chdir('../')\n",
    "    #print(layers_param)\n",
    "    return layers_param , layers\n",
    "\n",
    "\n",
    "def summary_string(model, input_size, batch_size=-1, device=torch.device('cpu'), dtypes=None):\n",
    "    if dtypes == None:\n",
    "        dtypes = [torch.FloatTensor]*len(input_size)\n",
    "\n",
    "    summary_str = ''\n",
    "    \n",
    "    def register_hook(module):\n",
    "        def hook(module, input, output):\n",
    "            class_name = str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "            module_idx = len(summary)\n",
    "            m_key = \"%s_%i\" % (class_name, module_idx + 1)\n",
    "            summary[m_key] = OrderedDict()\n",
    "            summary[m_key][\"input_shape\"] = list(input[0].size())\n",
    "            summary[m_key][\"input_shape\"][0] = batch_size\n",
    "            if isinstance(output, (list, tuple)):\n",
    "                summary[m_key][\"output_shape\"] = [\n",
    "                    [-1] + list(o.size())[1:] for o in output\n",
    "                ]\n",
    "            else:\n",
    "                summary[m_key][\"output_shape\"] = list(output.size())\n",
    "                summary[m_key][\"output_shape\"][0] = batch_size\n",
    "\n",
    "            params = 0\n",
    "            \n",
    "            if(module.__module__.startswith('torch.nn.modules')):\n",
    "                layer_index = len(layers_param)\n",
    "                l_key = \"%s_%i\" % (class_name, layer_index + 1)\n",
    "                layers_param[l_key] = OrderedDict()\n",
    "                layers_param[l_key][\"input_shape\"] = list(input[0].size())\n",
    "                layers_param[l_key][\"input_shape\"][0] = batch_size\n",
    "                layers_param[l_key][\"output_shape\"] = list(output.size())\n",
    "                layers_param[l_key][\"output_shape\"][0] = batch_size\n",
    "                layers.append(module)\n",
    "        \n",
    "            if hasattr(module, \"weight\") and hasattr(module.weight, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.weight.size())))\n",
    "                summary[m_key][\"trainable\"] = module.weight.requires_grad\n",
    "            if hasattr(module, \"bias\") and hasattr(module.bias, \"size\"):\n",
    "                params += torch.prod(torch.LongTensor(list(module.bias.size())))\n",
    "            summary[m_key][\"nb_params\"] = params\n",
    "\n",
    "        if (\n",
    "            not isinstance(module, nn.Sequential)\n",
    "            and not isinstance(module, nn.ModuleList)\n",
    "        ):\n",
    "            hooks.append(module.register_forward_hook(hook))\n",
    "\n",
    "    # multiple inputs to the network\n",
    "    if isinstance(input_size, tuple):\n",
    "        input_size = [input_size]\n",
    "\n",
    "    # batch_size of 2 for batchnorm\n",
    "    x = [torch.rand(2, *in_size).type(dtype).to(device=device)\n",
    "         for in_size, dtype in zip(input_size, dtypes)]\n",
    "\n",
    "    # create properties\n",
    "    layers = nn.ModuleList()\n",
    "    layers_param = OrderedDict()\n",
    "    summary = OrderedDict()\n",
    "    hooks = []\n",
    "\n",
    "    # register hook\n",
    "    model.apply(register_hook)\n",
    "\n",
    "    # make a forward pass\n",
    "    # print(x.shape)\n",
    "    model(*x)\n",
    "\n",
    "    # remove these hooks\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    summary_str += \"-------------------------------------------------------------------------------------\" + \"\\n\"\n",
    "    line_new = \"{:>20}  {:>25} {:>25} {:>15}\".format(\n",
    "        \"Layer (type)\", \"Output Shape\",\"Input Shape\", \"Param #\")\n",
    "    summary_str += line_new + \"\\n\"\n",
    "    summary_str += \"=====================================================================================\" + \"\\n\"\n",
    "    total_params = 0\n",
    "    total_output = 0\n",
    "    trainable_params = 0\n",
    "    for layer in summary:\n",
    "        # input_shape, output_shape, trainable, nb_params\n",
    "        line_new = \"{:>20}  {:>25} {:>25} {:>15}\".format(\n",
    "            layer,\n",
    "            str(summary[layer][\"output_shape\"]),\n",
    "            str(summary[layer][\"input_shape\"]),\n",
    "            \"{0:,}\".format(summary[layer][\"nb_params\"]),\n",
    "            \n",
    "        )\n",
    "        total_params += summary[layer][\"nb_params\"]\n",
    "\n",
    "        total_output += np.prod(summary[layer][\"output_shape\"])\n",
    "        if \"trainable\" in summary[layer]:\n",
    "            if summary[layer][\"trainable\"] == True:\n",
    "                trainable_params += summary[layer][\"nb_params\"]\n",
    "        summary_str += line_new + \"\\n\"\n",
    "\n",
    "    # assume 4 bytes/number (float on cuda).\n",
    "    total_input_size = abs(np.prod(sum(input_size, ()))\n",
    "                           * batch_size * 4. / (1024 ** 2.))\n",
    "    total_output_size = abs(2. * total_output * 4. /\n",
    "                            (1024 ** 2.))  # x2 for gradients\n",
    "    total_params_size = abs(total_params * 4. / (1024 ** 2.))\n",
    "    total_size = total_params_size + total_output_size + total_input_size\n",
    "    # return summary\n",
    "    # print(layers_param)\n",
    "    # print(\"hi\")\n",
    "    return layers_param , layers , summary_str, (total_params, trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61eb8280-6958-4005-afd9-46fac205086c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.ModuleList'>\n"
     ]
    }
   ],
   "source": [
    "layer_param , true_layers = summary(model, (3, 224, 224),batch_size = 1)\n",
    "print(type(true_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fe2cca0-c736-47f0-af70-6dfd8def4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_info_ext(layer_param , true_layers ):\n",
    "    os.chdir('./model_detail')\n",
    "    layer_info_extraction = ''\n",
    "    # create properties\n",
    "    layer_idx = 0\n",
    "    for layer in true_layers:\n",
    "        layer.eval()\n",
    "        layer_info_extraction += str(layer) + '\\n'\n",
    "        class_name = str(layer.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "        layer_idx += 1\n",
    "        m_key = \"%s_%i\" % (class_name, layer_idx)\n",
    "        layer_info_extraction += '    input : '+ str(layer_param[m_key]['input_shape']) + '\\n'\n",
    "        for param in layer.state_dict():\n",
    "            layer_info_extraction += '    ' \n",
    "            layer_info_extraction += param + ' '\n",
    "            layer_info_extraction += str(layer.state_dict()[param].size()) + '\\n'\n",
    "    \n",
    "    with open('layer_info.txt', 'w') as file:\n",
    "            file.write(layer_info_extraction)\n",
    "    os.chdir('../')\n",
    "    \n",
    "layer_info_ext(layer_param,true_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d08cab7a-c45d-4bef-bb30-dead020f0538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create properties\n",
    "def gen_input():\n",
    "    os.chdir('./input_weight')\n",
    "    layer_idx = 0\n",
    "    for layer in true_layers:\n",
    "        layer.eval()\n",
    "        class_name = str(layer.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "        layer_idx += 1\n",
    "        m_key = \"%s_%i\" % (class_name, layer_idx)\n",
    "        input_shape = layer_param[m_key]['input_shape']\n",
    "        input_data = torch.randn(*input_shape)\n",
    "        # print(layer_param[m_key]['input_shape'])\n",
    "        # print(input_data.shape)\n",
    "        # print(type(layer))\n",
    "        torch.save(input_data, f'{m_key}_input.pth')\n",
    "    os.chdir('../')\n",
    "\n",
    "gen_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c04eee30-c8cd-4a15-96b4-ba6b694dbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_golden():\n",
    "    os.chdir('./input_weight')\n",
    "    layer_idx = 0\n",
    "    for layer in true_layers:\n",
    "        class_name = str(layer.__class__).split(\".\")[-1].split(\"'\")[0]\n",
    "        layer_idx += 1\n",
    "        m_key = \"%s_%i\" % (class_name, layer_idx)\n",
    "        loaded_input_data = torch.load(f'{m_key}_input.pth')\n",
    "        module = layer.eval()\n",
    "        output = module(loaded_input_data)\n",
    "        os.chdir('../golden')\n",
    "        torch.save(output ,f'{m_key}_golden.pth')\n",
    "        os.chdir('../input_weight')\n",
    "    os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c20bb936-293e-4463-8622-8ae55535918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_golden()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
